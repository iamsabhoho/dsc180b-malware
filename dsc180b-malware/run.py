from src import utils
from src.model import model_androguard
from src.data import data_androguard
from src.analysis import andro_analysis
import sys
#from config import data_params
import numpy as np
import pandas as pd

import os, sys, inspect
import json


import os, sys, inspect
currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
sys.path.insert(0,parentdir)



DATA_PARAMS = 'config/data-params.json'
MODEL_PARAMS = 'config/model.json'
TEST_PARAMS = 'config/test.json'
FEATURE_PARAMS = "config/features.json"


currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))


def load_params(fp):
    with open(fp) as fh:
        param = json.load(fh)

    return param


def main(targets):
    """
    runs the targets
    targets --> a list of targets
    """

    #["data", "feature", "model", "train", "test", "makefile"
    if "data" in targets:
        data_config = load_params(DATA_PARAMS)
        stack = data.train_txt(data_config["benign"], data_config["malicious"], data_config["random"])
        dd = data.full_info(data_config["train_set"], "train")
        dd = data.full_info(data_config["test_set"], "test")
        print(dd)

        data.get_unique_apilist(data_config["train_data"])

        # process csv to get complete apis
        data.process_csv(data_config["train_data"], "src/data/csv/train_processed.csv")
        data.process_csv(data_config["test_data"],  "src/data/csv/test_processed.csv")


        # merge processed with unique api list to ease computation
        data.get_merged(data_config["train_processed"], data_config["unique_calls"], "src/data/csv/merged_train.csv")
        data.get_merged(data_config["test_processed"], data_config["unique_calls"], "src/data/csv/merged_test.csv")



    if "feature" in targets:
        feature_config = load_params(FEATURE_PARAMS)
        get_A(feature_config["train_merged"], "train")
        get_A(feature_config["train_merged"], "test")

        get_P(feature_config["train_merged"])
        get_B(feature_config["codeblocks_txt"], feature_config["unique_calls"])



    if 'test' in targets:
        with open(TEST_PARAMS) as fh:
            test_cfg = json.load(fh)

        benign_dir = test_cfg['test_benign']
        malicious_dir =test_cfg['test_malicious']
        
        target = test_cfg["test_outputs"]
        # get txt with labels:
        txt = os.path.join(target, "app_label_id.txt")
        
        if os.path.exists(txt):
            os.remove(txt)
            data_androguard.train_txt(malicious_dir, benign_dir, benign_dir, target)
        else:
            data_androguard.train_txt(malicious_dir, benign_dir, benign_dir, target)
        
        
        # run metapath2vec
        data = pd.read_csv(txt)
        filepaths, label = list(data.app_fp), list(data.app_label)
        
        
        bigX = []
        bigY = []
        
        for graph in range(len(filepaths)):
            X, y = data_androguard.metapath2vec(filepaths[graph], label[graph])
            for item in range(len(X)):
                bigX.append(X[item])
                bigY.append(y[item])
            
            
        baseline = model_androguard.model()
            
        
            
            
        
            
        

       
        
        
        
#         print("shape for raw api's: ", data.get_info_orig(benign_fullfp)[0].shape)
#         print("shape for codeblocks: ", data.get_info_orig(malicious_fullfp)[1].shape)



#         #features
#         X, y = data.get_baseline_features(benign_fullfp, malicious_fullfp)
#         print("features: \n", ["app","api_ct","size","codeblocks"])
#         print(X, y)
#         print("data built!")


#         baseline = model.model("SVM")
#         baseline.init_baseline(X, y)
#         print("model initialized!")

#         print("predictions: ")
#         print("in: ", [[1,2,3,4]], "out: ",baseline.clf.predict([[1,2,3,4]]))
#         print("in: ", [[4,4,3,2]], "out: ",baseline.clf.predict([[4,4,3,2]]))
#         print("in: ", [[4,0,0,1]], "out: ",baseline.clf.predict([[4,0,0,1]]))
#         print("in: ", [[9,9,3,2]], "out: ",baseline.clf.predict([[9,9,3,2]]))

    if ("train" in targets) or ("model" in targets):
        model_params = load_params(MODEL_PARAMS)
        kernels = model_params["kernel"]
        A_train = sparse.load_npz(model_params["A_train"])
        A_test = sparse.load_npz(model_params["A_test"])
        P = sparse.load_npz("src/data/features/P.npz")[:259265, :259265]
        B = sparse.load_npz("src/data/features/P.npz")[:259265, :259265]


        #labels:
        test_labels = np.loadtxt(model_params["test_labels"])
        train_labels = np.loadtxt(model_params["train_labels"])
        classifier = model.model(model_params["type"])
        for kernel in kernels:
            if "AA" == kernel:
                Train_AA = (A_train @ A_train.transpose())
                Test_AA = (A_test @ A_train.transpose())
                print("score for kernel AA")
                print(classifier.clf.fit(Train_AA, train_labels))
                print(classifier.clf.score(Test_AA, test_labels))

            elif "ABA" == kernel:
                Train_ABA = (A_train @ B @ A_train.transpose())
                Test_ABA = (A_test @ B @ A_train.transpose())
                print("score for kernel ABA")
                print(classifier.clf.fit(Train_ABA, train_labels))
                print(classifier.clf.score(Test_ABA, test_labels))

            elif "APA" == kernel:
                Train_APA = (A_train @ P @ A_train.transpose())
                Test_APA = (A_test @ P @ A_train.transpose())
                print("score for kernel APA")
                print(classifier.clf.fit(Train_APA, train_labels))
                print(classifier.clf.score(Test_APA, test_labels))

            elif "APBPA" == kernel:
                Train_APBPA = (A_train @ P @ B @ P.transpose() @ A_train.transpose())
                Test_APBPA = (A_test @ P @ B @ P.transpose() @ A_train.transpose())
                print("score for kernel APBPA")
                print(classifier.clf.fit(Train_APBPA, train_labels))
                print(classifier.clf.score(Test_APBPA, test_labels))



    return None


if __name__ == "__main__":
    target = sys.argv[1:]
    main(target)
