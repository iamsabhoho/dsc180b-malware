{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from androguard import misc\n",
    "from androguard import session\n",
    "from stellargraph import StellarGraph\n",
    "import networkx as nx\n",
    "from androguard.core.analysis import auto\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data_androguard as data\n",
    "# metapath2vec stuff\n",
    "from stellargraph.data import UniformRandomMetaPathWalk\n",
    "from stellargraph.data import UniformRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import itertools\n",
    "from scipy import spatial\n",
    "\n",
    "# https://piazza.com/class/kfw6j5mmmf07b9?cid=365\n",
    "# getting utils\n",
    "import sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "import utils\n",
    "from model import model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# autoloader stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_apks_fp = \"/teams/DSC180A_FA20_A00/a04malware/apks/malware\"\n",
    "malware_apks = [os.path.join(malware_apks_fp, item) for item in os.listdir(malware_apks_fp)]\n",
    "benign_fp = \"/teams/DSC180A_FA20_A00/a04malware/personal-group03/benign_graphs_sab/popular_apks\"\n",
    "benign_apks = [os.path.join(benign_fp, item) for item in os.listdir(benign_fp)]\n",
    "\n",
    "\n",
    "\n",
    "g1 = data.API_abstraction_vectorized(malware_apks[0], \"\", \"CLASS\", \"NX\", True)\n",
    "g2 = data.API_abstraction_vectorized(malware_apks[1], \"\", \"CLASS\", \"NX\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linesentenceFP = \"/teams/DSC180A_FA20_A00/a04malware/personal-group03/intermediate_files/m2v_walk_combined.txt\"\n",
    "linesentence = LineSentence(linesentenceFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_files = \"/teams/DSC180A_FA20_A00/a04malware/personal-group03/intermediate_files/\"\n",
    "\n",
    "df = pd.read_csv(app_id_fp)\n",
    "\n",
    "walks = []\n",
    "with open(os.path.join(intermediate_files, (\"m2v_walk_combined.txt\")), 'a') as file:\n",
    "    for row in tqdm(range(len(df))):\n",
    "        app_fp = df.iloc[row][\"app_fp\"]\n",
    "        app_label = df.iloc[row][\"app_label\"]\n",
    "        directory, app_name = utils.dir_and_app(app_fp)\n",
    "\n",
    "        metapath_fp = os.path.join(metapathsFP, (app_name+\"m2v_metapaths.txt\"))\n",
    "        walk_fp = os.path.join(walksFP, (app_name + \"m2v_walks.txt\"))\n",
    "        if os.path.exists(walk_fp) & os.path.exists(metapath_fp):\n",
    "            walk = data.unstack_walks(walk_fp, app_name)\n",
    "            for line in walk:\n",
    "                process = \" \".join(line)\n",
    "                file.write(process)\n",
    "        \n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in walk:\n",
    "    print(\" \".join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "\n",
    "# Load data\n",
    "\n",
    "doc1 = [\"This is a sentence\", \"This is another sentence\"]\n",
    "\n",
    "# Transform data (you can add more data preprocessing steps) \n",
    "\n",
    "docs = []\n",
    "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "for i, text in enumerate(doc1):\n",
    "    words = text.lower().split()\n",
    "    tags = [i]\n",
    "    docs.append(analyzedDocument(words, tags))\n",
    "\n",
    "# Train model (set min_count = 1, if you want the model to work with the provided example data set)\n",
    "\n",
    "model = doc2vec.Doc2Vec(docs, size = 100, window = 300, min_count = 1, workers = 4)\n",
    "\n",
    "# Get the vectors\n",
    "\n",
    "model.docvecs[0]\n",
    "model.docvecs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks_app[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks_app[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(app_id_fp)\n",
    "df[df.app_fp.str.contains(\"28b8b57005af1a6ed1b05e2c6c732942\")].app_label.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc, appname = utils.dir_and_app('/teams/DSC180A_FA20_A00/a04malware/personal-group03/actualdroid_intermediate_files/metapath2vec_walks/28b8b57005af1a6ed1b05e2c6c732942m2v_walks.txt')\n",
    "\n",
    "appname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [np.loadtxt(walks_app[0], dtype = object)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[TaggedDocument(doc, [i]) for i, doc in enumerate(documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data = [\"I love machine learning. Its awesome.\",\n",
    "        \"I love coding in python\",\n",
    "        \"I love building chatbots\",\n",
    "        \"they chat amagingly well\"]\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
