from androguard import misc
from androguard import session
from stellargraph import StellarGraph
import networkx as nx
from androguard.core.analysis import auto
from datetime import datetime
import sys
import os
import pandas as pd
import numpy as np
import itertools

# metapath2vec stuff
from stellargraph.data import UniformRandomMetaPathWalk
from gensim.models import Word2Vec



# concurrency
import concurrent.futures

## getting utils
import sys,inspect
currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
sys.path.insert(0,parentdir)
import utils




# txt file for apps
def train_txt(malware, benign1, benign2, target):
    """
    benign_fp --> file path for directory of benign_apps
    mali_fp --> file path for directory of malicious apps

    Assigns an ID to each app

    output --> train.txt containing train apps, columns = app_ID, app_fp, label
    """

    benign_apps = [os.path.join(benign1, bee) for bee in os.listdir(benign1)] + \
    [os.path.join(benign2, bee) for bee in os.listdir(benign2)]
    benign_labels = [0] * len(benign_apps)
    print(len(benign_apps))

    # note, malware are already CFGs
    malware_apps = [os.path.join(malware, bee) for bee in os.listdir(malware)]
    malware_labels = [1] * len(malware_apps)
    print(len(malware_apps))

    apps = benign_apps + malware_apps
    labels = benign_labels + malware_labels

    # app ID's
    app_id = range(0, (len(benign_apps) + len(malware_apps)))

    csv = pd.DataFrame({
        "app_fp":apps,
        "app_label":labels,
        "app_ID":app_id
    })
    
    # build outputfp: 
    outfp = os.path.join(target, "app_label_id.txt")
    if os.path.exists(outfp) & (".txt" in outfp):
        os.remove(outfp)
    csv.to_csv(outfp, index = False)
    return csv


##################### ETL (EXTRACTING, TRANSFORMING, LOADING DATA) ####################



#     futures = []
#     with ThreadPoolExecutor(8) as executor:

#         for directory in directories:
#             filepaths = os.listdir(directory)
#             for filepath in filepaths:
#                 real_p = os.path.join(directory, filepath)
#                 now = datetime.now()
#                 futures.append(executor.submit(decompile_apk, real_p, target))
#         for job in as_completed(futures):
#             results = job.result()

def read_graph_process(fp):
    '''
    reads and decompresses .gml.bz2 file to obtain the graph
    
    fp --> filepath to .gml.bz2 file (should be the graph)
    '''
    # get app name
    direc, app = os.path.split(fp)
    app = app.replace(".gml.bz2", "")
    
    graph = nx.read_gml(fp)
#     graph.add_nodes_from([
#         app, {""}
#     ])
    
#     stellar = StellarGraph.from_networkx(graph, node_type_attr= 'type')
    return graph

def etl(directories, target):
    """
    perform ETL on directories, outputs to targets

    ETL process:
    1. apk --> decompile to a, d, dx
    2. a, d, dx --> dx.get_call_graph() (networkx object)
    3. perform feature extraction on (networkx object)
    4. export networkx object as a compressed .gml file

    directory --> directories containing the apps we want to get graphs from
    target --> outputs folder .gml.bz2 files to a target destination
    """

#     for directory in directories:
#         filepaths = os.listdir(directory)
#         for filepath in filepaths:
#             real_p = os.path.join(directory, filepath)
#             decompile_apk(real_p, target)

    for directory in directories:
        
        settings = {
            "my" : AndroTest(directory),
            "log":auto.DefaultAndroLog,
            "max_fetcher":3
        }

        aa = auto.AndroAuto(settings)
        aa.go()
        
def API_abstraction(kind, api):
    """
    Abstracts an API call
    
    kind --> What level of abstraction
    api --> the API call to abstract, an array of data
    """
    if type(api) != str:
        node, data = api
        if kind == "CLASS": # class level abstraction 
            # classes are formatted as Lclassname;
            # e.g., Ljava/lang/String;
            api_class = node.split()[0]
            return (api_class, data)
    else:
        api_class = api.split()[0]
        return api_class
    
def add_apk_node(G, appname): 
    """
    Adds the apk node to the graph, along with the various
    G --> the networkx graph object that we are adding app node to 
    appname --> the name of the app, if blank, it'll just add "apk"
    """
    
    if appname == "":
        G.add_nodes_from([("apk", {"type":"APK,Node"})])
        nx_nodes = np.array(G.nodes())
        edgesto = [("apk", node) for node in nx_nodes]
        edgesfrom = [(node, "apk") for node in nx_nodes]
        G.add_edges_from(edgesto)
        G.add_edges_from(edgesfrom)
    else:
        G.add_nodes_from([(appname, {"type":"APK,Node"})])
        nx_nodes = np.array(G.nodes())
        edgesto = [(appname, node) for node in nx_nodes]
        edgesfrom = [(node, appname) for node in nx_nodes]
        G.add_edges_from(edgesto)
        G.add_edges_from(edgesfrom)
        
    return G
        
        

def edge_processing(kind, edge):
    """
    processes the edges so they are abstracted to some level
    returns a new edge (tuple) that is processed
    """
    
    api1, api2, weight = edge

    processed1, processed2 = API_abstraction(kind, api1), API_abstraction(kind, api2)
    return (processed1, processed2, weight)
    
        
def API_abstraction_vectorized(inFP, outFP, kind, to_return):
    """
    abstracts edges and nodes of ONE APP to some level
    
    returns a graph that is abstracted (WILL CHANGE)
    
    inFP --> input file path (should be .gml.bz2)
    outFP --> output directory
    kind --> (str) FAMILY or PACKAGE or CLASS
    """
    
    # getting the app name
    direc, app_name = utils.dir_and_app(inFP)

    try:
        networkx = nx.read_gml(inFP)
    except:
        return inFP + " might be broken!"

    nx_nodes = np.array(networkx.nodes(data = True))
    nx_edges = np.array(networkx.edges, dtype = object)
    node_vfunc = np.vectorize(API_abstraction)
    edge_vfunc = np.vectorize(edge_processing)

    newnodes = [API_abstraction(kind, node) for node in nx_nodes]
    newedges = [edge_processing(kind, edge) for edge in nx_edges]

    G = nx.MultiDiGraph()
    G.add_nodes_from(newnodes)
    G.add_edges_from(newedges)
    G = add_apk_node(G, "")
    stellar = StellarGraph.from_networkx(G, node_type_attr = "type")
    if to_return == "NX":
        return G
    elif to_return == "SG":
        return stellar
    

def dfs(visited, graph, node, path = []):
    """
    performs DFS on the graph, prints traversal
    
    """
    if node not in visited:
        path.append(graph.node_type(node))
        visited.add(node)
        for neighbor in graph.out_nodes(node):
            dfs(visited, graph, neighbor, path)
        
        
    return path
    
def metapath_builder_nodetype(node_types):
    """
    builds some metapaths using given nodetypes
    """
    node_types.remove("APK,Node")
    return [(["APK,Node"] + list(item) + ["APK,Node"]) for item in list(itertools.permutations(node_types))]
     
    
    


def metapath2vec(G, walk_length, metapaths):
    """
    performs metapath2vec and returns representations with labels
    
    G --> stellargraph object of the graph
    label --> (0 or 1) benign or not
    walk_length --> int, defines how long the sentences should be
    """
    rw = UniformRandomMetaPathWalk(G)
    walks =rw.run(
        nodes = list(G.nodes()),
        length = walk_length,
        n = 1,
        metapaths = metapaths
    
    )
    
    model = Word2Vec(walks, size = 128, window = 5, min_count = 0, sg = 1)
    return model.wv
    
    
    
def wrapper(graph_fp, outFP):
    """
    wrapper function for everything, will output for 1 app
    
    graph_fp --> the graph file path we have
    label --> label for the graph
    """
    direc, app_name = utils.dir_and_app(graph_fp)
    outputfp = os.path.join(outFP, (app_name + "m2v_embedding"+ ".txt"))
    if os.path.exists(outputfp):
         print(app_name + " is already finished!")
    else:
        try:
            stellar = API_abstraction_vectorized(graph_fp, "", "CLASS", "SG")
            perms = metapath_builder_nodetype(stellar.node_types)
            m2v = metapath2vec(stellar, 100, perms)
            apk_embedding = m2v.get_vector("apk")
            
            np.savetxt(outputfp, apk_embedding, fmt = "%s")
            print("the app: ", graph_fp, " is done!")
        except:
            print("the app: ", graph_fp, " might be broken!")
            
            
def create_embeddings(directory, target_dir):
    """
    create m2v embeddings of graphs
    
    """
    
    wrapper_vectorized = np.vectorize(wrapper)
    
    apps = os.listdir(directory)[:5]
    
    results = wrapper_vectorized(apps, target_dir)
    return ("Finished for directory: " + directory)
    
    
    
   
    
    


            


if __name__ == "__main__":

    # ur username: change here
    USER = "edh021"


    # target
    target = utils.get_to_directory(USER, ["DSC180A_FA20_A00", "a04malware", "personal-group03", "actualdroid_intermediate_files", "metapath2vec_outputs"])
    
    malware = "/teams/DSC180A_FA20_A00/a04malware/apks/malware"
    create_embeddings(malware, target)
    now = datetime.now()
    
    print("5 same apps took: ", (datetime.now() - now))
