
import numpy as np
import json
import csv
import os
import re
from tqdm import tqdm
from glob import glob
import pandas as pd
from scipy import sparse

import sys,inspect
currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
sys.path.insert(0,parentdir)

import utils



from concurrent.futures import ThreadPoolExecutor

# get project directory
PROJECTDIR = os.path.dirname(parentdir)



## baseline
def baseline_helper(dct, full_fp, app):
    """
    helper for baseline, adds information to dictionary via a file path (fp)
    and then outputs the dictionary again

    dct keys must be the same as the ones in get_baseline_features!
    """
    executor = ThreadPoolExecutor(8)
    future = executor.submit(get_info_orig, (full_fp))
    information = future.result()

    dct['app'].append(len(app))

    # size of the app
    size = os.path.getsize(full_fp)
    dct["size"].append(size)

    # number of distinct API calls
    apicount = len(information[0])
    dct["api_ct"].append(apicount)

    #number of codeblocks
    code_ct = len(information[1])
    dct['codeblocks'].append(code_ct)
    return dct

def get_baseline_features(benign_fp, malicious_fp):
    '''
    gets the baseline features
    counts of API calls, size, number of codeblocks
    '''

    labels = []
    dct = {
        "app":[],
        "api_ct":[],
        "size":[],
        "codeblocks":[]
    }

    benign_apps = os.listdir(benign_fp)
    malicious_apps = os.listdir(malicious_fp)


    for benign in benign_apps:
        full_fp = benign_fp + "/" + benign
        dct = baseline_helper(dct, full_fp, benign)

        #label for benign = 0
        labels.append(0)

    for mali in malicious_apps:
        full_fp = malicious_fp + "/" + mali
        dct = baseline_helper(dct, full_fp, mali)
        # label for malware is 1
        labels.append(1)


    output = np.array([list(inner_dict) for inner_dict in dct.values()]).T


    return output, np.array(labels)
###################################################################################
###################################################################################
######################### SVM METHODS #############################################
###################################################################################
###################################################################################

# create txt containing the apps and their labels
def train_txt(benign_fp, mali_fp, random_fp):
    """
    benign_fp --> file path for directory of benign_apps
    mali_fp --> file path for directory of malicious apps

    output --> train.txt containing train apps, columns = app_ID, app_fp, label
    """
    benign_apps = [(benign_fp + bee) for bee in os.listdir(benign_fp)]
    benign_labels = [0] * len(benign_apps)

    varieties = next(os.walk(mali_fp))[1]

    mali_apps = []
    test_mali = []
    ct = 0
    for app in varieties:
        vs = next(os.walk(mali_fp + app))[1]
        for v in vs:
            lst = glob(mali_fp + app + '/' + v + '/*')
            for item in lst:
                if ct < 300:
                    mali_apps.append("%s" % item)
                    ct += 1
                elif (ct >= 300) and (ct < 400):
                    test_mali.append("%s" % item)
                    ct += 1
                elif ct > 400:
                    break


    mali_labels = [1] * len(mali_apps)
    test_mali_labels = [1] * len(test_mali)

    stack = np.array([
        np.arange(len(benign_apps)+len (mali_apps)),
        (benign_apps + mali_apps),
        (benign_labels + mali_labels)]).T

    np.savetxt("file_paths/train.csv",stack,delimiter = ",", fmt = '"%s"')

    # make test_data
    test_benign = [(random_fp + bee) for bee in os.listdir(random_fp)][:150]
    test_benign_labels = [0] * len(test_benign)
    np.savetxt("features/labels_test.txt", np.array(test_benign_labels + test_mali_labels, dtype = int),delimiter = ",")
    np.savetxt("features/labels_train.txt", np.array(benign_labels + mali_labels, dtype = int),delimiter = ",")



    wwstack = np.array([
        np.arange(len(test_benign)+len (test_mali)),
        (test_benign + test_mali),
        (test_benign_labels + test_mali_labels)]).T
    np.savetxt("file_paths/test.csv",wwstack,delimiter = ",", fmt = '"%s"')


    return stack

def process_csv_helper(string):
    """turns a string into the actual api"""
    find = re.findall(r"L[\/\d\w;]*-{1}>{1}.*", string)

    if len(find) >= 1:
        return find[0]
    else:
        return ""



def process_csv(csv_fp, outputfp):
    """
    processing csv's with pandas, should have two columns
    should take in csv of 2 columns, (appid, api_call)

    outputname --> output the name that we save csv as
    """
    df = pd.DataFrame()
    temp = pd.read_csv(csv_fp,iterator = True, chunksize= 5000)
    df = pd.concat(temp)
    df.columns = ["appid", "api_call"]
    df = df[df.api_call.str.contains("->")]
    df.api_call = df.api_call.apply(process_csv_helper)
    df = df.dropna()
    df = df.reset_index(drop = True)

    df.to_csv(outputfp)



def get_unique_apilist(train_api, output_fp = "csv/api_ids.csv"):
    """
    train_api --> the csv containing appid along with their api_calls
    run for train only

    """

    for train in pd.read_csv(train_api, chunksize = 20000000):
        break

    train = train.dropna()

    gg = train.api_call.unique()

    stack = np.vstack(
    [np.arange(len(gg)),
    gg]
    ).T

    np.savetxt(output_fp, stack, delimiter = ",", fmt = '"%s"' )


def get_merged(processed_csv, unique_api, outputfp = "csv/merged_train.csv"):
    """merges apiID to appid to ease computation"""

    train = pd.DataFrame()
    temp = pd.read_csv(processed_csv,iterator = True, chunksize= 5000)
    train = pd.concat(temp)
    train = train.dropna()

    api = pd.read_csv(unique_api, header = None)
    api.columns = ["api_id", "api_call"]
    api = api.dropna()

    train = train.merge(api, on = "api_call", how = "left").dropna()
    train = train.reset_index(drop = True)

    train.api_id = train.api_id.astype(int)

    train[["appid", "api_id"]].to_csv(outputfp)




def get_info(fp, appid, ver):
    '''
    fp --> file path containing smali files of app (fp of app)

    get unique api's of smalis for the training set
    '''
    raw = []
    apis = []
    codeblocks = []


    for subdir, dirs, files in os.walk(fp):
        for filename in files:
            fp = subdir + os.sep + filename
            if fp.endswith(".smali") or fp.endswith(".smali"):
                with open(fp, encoding = "utf-8") as file:
                    f = file.read()

                    raw = np.array(re.findall(r"invoke-.+\s?L.*;", f), dtype = object)
                    raw_ind = np.array([appid] * len(np.unique(raw)))
                    codeblocks = np.array(re.split("\.method", f), dtype = object)
                    codeblock_ind = np.array([appid] * len(codeblocks))



                    with open("csv/%s_api_calls_w_appid.csv"%ver, "a") as api_txt:
                        np.savetxt(api_txt, np.vstack((raw_ind, np.unique(raw))).T,delimiter = ",", fmt = '"%s"')
                    api_txt.close()

                    with open("csv/%s_codeblocks_w_appid.csv"%ver, "a") as codeblock_txt:
                        np.savetxt(codeblock_txt, np.vstack((codeblock_ind, codeblocks)).T,delimiter = ",", fmt = '"%s"')
                    codeblock_txt.close()


#                     apis = apis + re.findall("(L[\/\d\w(->)]*\;)", f)

                file.close()
    return None

def get_info_orig(fp):
    '''
    smalis --> a list of APK's from smalis
    get unique api's of smalis
    get codeblocks as well
    '''
    raw = []
    apis = []
    codeblocks = []


    for subdir, dirs, files in os.walk(fp):
        for filename in files:
            fp = subdir + os.sep + filename
            if fp.endswith(".smali") or fp.endswith(".smali"):
                with open(fp, encoding = "utf-8") as file:
                    f = file.read()
                    raw = raw + re.findall(r"invoke-.+\s?L.*;", f)
#                     apis = apis + re.findall("(L[\/\d\w(->)]*\;)", f)
                    codeblocks = codeblocks + re.split("\.method", f)
                file.close()

    return [np.array(raw), np.array(codeblocks, dtype = object)]



def get_A(processed_apis, ver):
    """
    processed --> appid along with its API CALLS as api_id, should have columns (appid, api_id)


    For A matrix:
    row --> number of apps
    columns --> api call index
    Aij = 1 if api is in App
    """
    processed = pd.read_csv(processed_apis)
    apps = processed.appid.unique()
    maxi = np.max(apps)

    A = np.zeros(((maxi+1), 259265))

    for app in apps:
        A[app][processed[processed.appid == app]["api_id"].unique()] = 1

    sparse.save_npz("features/A_%s"%ver,sparse.csr_matrix(A))

    return A[np.sum(A, axis = 1) > 1]


def get_P(unique_apis):
    """
    unique_apis --> .csv file with all unique api calls
    """

    train = pd.DataFrame()
    temp = pd.read_csv(unique_apis,iterator = True, chunksize= 5000, header = None)
    train = pd.concat(temp)
    train = train.dropna()
    train.columns = ["apiid", "api_call"]
    train.api_call = train.api_call.apply(lambda x: x.split("->")[0])


    P = sparse.lil_matrix((259265,259265))
#     with open("required/P.csv")

    for i in tqdm(range(train.shape[0]+1)):
        P[i] = (np.roll(train.api_call, -i) == np.array(train.api_call)).astype(int)

    sparse.save_npz("features/P",sparse.csr_matrix(P))



    return None




def get_B(codeblocks_txt, apilist_txt):
    """
    apilist_txt --> txt file for the unique api's
    codeblocks_txt --> txt file for codeblocks in apps
    """
    train = pd.DataFrame()
    temp = pd.read_csv("required/api_ids.csv",iterator = True, chunksize= 5000, header = None)
    train = pd.concat(temp)
    train = train.dropna()
    apis = np.array(train)

    B = sparse.lil_matrix((259265, 259265))
    with open(codeblocks.txt, "r") as file:
        for line in file:
            app_id, content = line.split(",")
            find = re.findall(r"L[\/\d\w;]*-{1}>{1}.*", content)
            if len(find) > 1:
                ind = []
                for i in len(apis):
                    if apis[i] in find:
                        ind.append(i)
                for j in ind:
                    for k in ind:
                        B[j, k] = 1
    file.close()

    sparse.save_npz("features/B",sparse.csr_matrix(B))
    return None








def get_codeblocks(fp):
    '''
    gets all the codeblocks in a file path (fp)
    '''
    codeblocks = []

    for subdir, dirs, files in os.walk(fp):
        for filename in files:
            fp = subdir + os.sep + filename
            if fp.endswith(".smali") or fp.endswith(".smali"):
                with open(fp, encoding = "utf-8") as file:
                    f = file.read()
                    codeblocks = codeblocks + re.split("\.method", f)
                file.close()
    return codeblocks




def info_for_apps(txt):
    '''
    fp --> file path containing smali files of app (fp of app)

    get unique api's of smalis
    '''
    raw = []
    apis = []
    codeblocks = []

    apps = []
    with open('file_paths/train.csv', "r", newline = '') as file:
        reader = csv.reader(file)
        apps = list(reader)
    file.close()


    for appid, appfp, label in apps:
        print("Processing on appid: ", appid)
        for subdir, dirs, files in os.walk(appfp):
            for filename in files:
                fp = subdir + os.sep + filename
                if fp.endswith(".smali") or fp.endswith(".smali"):
                    with open(fp, encoding = "utf-8") as file:
                        f = file.read()

                        raw = np.array(re.findall(r"invoke-.+\s?L.*;", f), dtype = object)
                        codeblocks = np.array(re.split("\.method", f), dtype = object)

                        with open("app_csv/app_%sapi_calls.csv"%appid, "a") as api_txt:
                            np.savetxt(api_txt, np.unique(raw),delimiter = ",", fmt = '"%s"')
                        api_txt.close()

                        with open("app_csv/app_%scodeblocks.csv"%appid, "a") as codeblock_txt:
                            np.savetxt(codeblock_txt, codeblocks,delimiter = ",", fmt = '"%s"')
                        codeblock_txt.close()


                    file.close()
    return "Done!"



def full_info(txt, ver):
    '''
    txt --> fp to training apps txt
    gets the full unique list of api calls

    '''

    apis = np.array([0], dtype = object)


    with open(txt, "r") as file:
        for info in file:
            line = info.replace("\"", "")
            app_id, app_fp, label = info.split(",")

            #process strings
            app_id = app_id.replace("\"", "")
            app_fp = app_fp.replace("\"", "")
            label = label.replace("\"", "")
            label = int(label.strip())

            executor = ThreadPoolExecutor(8)
            print("fp: ", app_fp, "appid: ", app_id)
            future = executor.submit(get_info, app_fp, app_id, ver)
            future.result()

#             apis = np.concatenate((apis, api))
    file.close()


#     apis = np.unique(apis)
#     ind = np.arange(len(apis))
#     zippo = np.vstack((ind, apis)).T
#     np.savetxt("full_csv/raw_calls.csv", zippo, delimiter = ",", fmt = '"%s"')

    return "Saved to csv folder"



def individual_api(fp):

    '''returns individual apis'''
    apis = []
    for subdir, dirs, files in os.walk(fp):
        for filename in files:
            fp = subdir + os.sep + filename
            if fp.endswith(".smali") or fp.endswith(".smali"):
                with open(fp, encoding = "utf-8") as file:
                    f = file.read()
                    apis = apis + re.findall("(L[\/\d\w(->)]*\;)", f)
                file.close()
    return np.array(apis)

def get_apis(codeblock, apilist):
    '''
    returns a indices of API's from a string of codeblock

    '''
    inds = []

    apis = re.findall("(L[\/\d\w(->)]*\;)", codeblock)
    for api in apis:
        if api in apilist:
            inds.append(np.where(apilist == api)[0][0])
    return inds

def get_package(api):
    '''
    returns the package for an api
    note that the package name is the first element
    when we split the api by ->
    '''
    split = re.split("->", api)
    return split[0]





#     return [np.array(raw), np.array(codeblocks, dtype = object)]




def create_data(benign, malicious):
    '''
    benign --> the file path to the directory of benign files
    malicious --> file path to directory of malicious files
    '''

    # first, create csv's from filepaths

    benign_apps = [i for i in os.listdir(benign)]
    malicious_apps = [i for i in os.listdir(malicious)]

    for app in range(len(benign_apps)):
        fullfp = benign + "/" + benign_apps[app]
        print("filepath: ", fullfp)

        executor = ThreadPoolExecutor(8)
        future = executor.submit(get_info, fullfp)
        raw, apis, codeblocks = future.result()

        zippo = np.vstack((raw_ind, raw)).T
        np.savetxt("csv/benign_app_%d_raw_calls.csv" %app, zippo, delimiter = ",", fmt = '"%s"')

        apis_ind = np.arange(len(apis))
        zippo = np.vstack((apis_ind, apis)).T
        np.savetxt("csv/benign_app_%d_api_calls.csv" %app, zippo, delimiter = ",", fmt = '"%s"')

        codeblok_ind = np.arange(len(codeblocks))
        zippo = np.vstack((codeblok_ind, codeblocks)).T
        np.savetxt("csv/benign_app_%d_codeblocks.csv" %app, zippo, delimiter = ",", fmt = '"%s"')


    for app in range(len(malicious_apps)):
        fullfp = malicious + "/" + malicious_apps[app]
        print("filepath: ", fullfp)
        executor = ThreadPoolExecutor(8)
        future = executor.submit(get_info, fullfp)
        raw, apis, codeblocks = future.result()

        raw_ind = np.arange(len(raw))
        zippo = np.vstack((raw_ind, raw)).T
        np.savetxt("csv/mali_app_%d_raw_calls.csv" %app, zippo, delimiter = ",", fmt = '"%s"')

        apis_ind = np.arange(len(apis))
        zippo = np.vstack((apis_ind, apis)).T
        np.savetxt("csv/mali_app_%d_api_calls.csv" %app, zippo, delimiter = ",", fmt = '"%s"')

        codeblok_ind = np.arange(len(codeblocks))
        zippo = np.vstack((codeblok_ind, codeblocks)).T
        np.savetxt("csv/mali_app_%d_codeblocks.csv" %app, zippo, delimiter = ",", fmt = '"%s"')
    return None




def train_test_(apilist_fp, benign_fp, mali_fp):
    '''
    creates X_train and y_train
    apilist_fp --> file path to csv of all apilists
    benign_fp --> fp to benign apps
    mali_fp --> fp to malicious apps
    '''
    # labels: malicious = 1, benign = 0

    X_train = []
    y_train = []

    csv_fp = "csv/"
    for csv in os.listdir(csv_fp):
        if ".csv" in csv: # only look at .csv
            if "benign" in csv:
                X_train.append(csv)
                y_train.append(0)
            elif "mali" in csv:
                X_train.append(csv)
                y_train.append(1)
    return X_train, y_train


if "__name__" == "__main__":
    benign_fp = "/teams/DSC180A_FA20_A00/a04malware/popular-apps/"
    mali_fp = "/teams/DSC180A_FA20_A00/a04malware/malware/"
    random_fp = "/teams/DSC180A_FA20_A00/a04malware/random-apps/"
    # printing some stats of the dataset that we are gonna be working on
    print("# of benign apps: ", len(os.listdir(benign_fp)))
    print("# of malicious apps: ", len(os.listdir(mali_fp)))

    ## get train txt
    stack = train_txt(benign_fp, mali_fp,random_fp)
